{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "XLNet_FineTuning_Experiments.ipynb",
   "provenance": [
    {
     "file_id": "1UYNHNkk5Yq_dgIhRiVEFiswGzUJ-pdgs",
     "timestamp": 1583167071972
    }
   ],
   "collapsed_sections": [],
   "authorship_tag": "ABX9TyPl3j/tpNl0n6pgDydM9tcm"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "053ab367f8a640c3966e2143370b2063": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_114898f4262a4c219e3cad861bf2da41",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_15ec6e25b60e4759b7ccf2fb8dc9e714",
       "IPY_MODEL_4f71bed18e8c4384a5a82b32b9c67b64"
      ]
     }
    },
    "114898f4262a4c219e3cad861bf2da41": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "15ec6e25b60e4759b7ccf2fb8dc9e714": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_b16fb8dbc9e84100964be999cd468fce",
      "_dom_classes": [],
      "description": "Downloading: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 760,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 760,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_25a4e3418e5a4158937b1c968b33e2fb"
     }
    },
    "4f71bed18e8c4384a5a82b32b9c67b64": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_915f004a14784db3ae8edfaecd1c094a",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "â€‹",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 760/760 [00:00&lt;00:00, 4.02kB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_9d89bb9f68ed4ea89304489fc9dd7a84"
     }
    },
    "b16fb8dbc9e84100964be999cd468fce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "25a4e3418e5a4158937b1c968b33e2fb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "915f004a14784db3ae8edfaecd1c094a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "9d89bb9f68ed4ea89304489fc9dd7a84": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "943a59bf412149e3a1ff863a1f1f8118": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_387e66c97e1c43e9bbc472b9cd82d657",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_b6decf24faf94ef0ab431ada40f5d21b",
       "IPY_MODEL_ee40cf43e58348fa8bc3d734ee8b80c4"
      ]
     }
    },
    "387e66c97e1c43e9bbc472b9cd82d657": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "b6decf24faf94ef0ab431ada40f5d21b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_e2a9aeaefb49472c8126b3571a0cdeb7",
      "_dom_classes": [],
      "description": "Downloading: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 467042463,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 467042463,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_f24715c13e4c4ec29074241d8200d10b"
     }
    },
    "ee40cf43e58348fa8bc3d734ee8b80c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_7dc778ad60cf456799843c543d5f1008",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "â€‹",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 467M/467M [00:20&lt;00:00, 23.1MB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_7991961b6aad4309860eec2a3edda7c5"
     }
    },
    "e2a9aeaefb49472c8126b3571a0cdeb7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "f24715c13e4c4ec29074241d8200d10b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "7dc778ad60cf456799843c543d5f1008": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "7991961b6aad4309860eec2a3edda7c5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "800f6695490d461c89c2b4a0501388b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_d05b819f02fc4c9c895d4776521494a1",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_e92c3a3a104a4b0ea9492e9b33952426",
       "IPY_MODEL_a60a0eca898b417ab3e4aabcac1f972a"
      ]
     }
    },
    "d05b819f02fc4c9c895d4776521494a1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "e92c3a3a104a4b0ea9492e9b33952426": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_cc32eda257914339a6e2123d38b6e100",
      "_dom_classes": [],
      "description": "Downloading: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 798011,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 798011,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_bf67f5e965e54f92aa5f0f711ec2afd9"
     }
    },
    "a60a0eca898b417ab3e4aabcac1f972a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_1901ef9bf4f04252bd2f8a95c215f580",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "â€‹",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 798k/798k [00:14&lt;00:00, 54.5kB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_f535afc3db9649b7b683d8476e5061dc"
     }
    },
    "cc32eda257914339a6e2123d38b6e100": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "bf67f5e965e54f92aa5f0f711ec2afd9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "1901ef9bf4f04252bd2f8a95c215f580": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "f535afc3db9649b7b683d8476e5061dc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "c4f7eabf95c94cb3947d76a4752d24ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_d92fa367242c4f6dba668b69ee39ee00",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_86ff0c90d30946f8869ef8e45adf2f3e",
       "IPY_MODEL_7fcb9842c3ea405f8b1bb20b38003c4e"
      ]
     }
    },
    "d92fa367242c4f6dba668b69ee39ee00": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "86ff0c90d30946f8869ef8e45adf2f3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_ae9ffbbe7d3b4f10aa28c43713059046",
      "_dom_classes": [],
      "description": "100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 20712,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 20712,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_a0c1686dfae94710a21d5f49d56f5af5"
     }
    },
    "7fcb9842c3ea405f8b1bb20b38003c4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_00e9cbd42fa9422ab8c99f4596f5b8a4",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "â€‹",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 20712/20712 [1:11:36&lt;00:00,  4.82it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_eaafce605a844b378df4911e61553fdb"
     }
    },
    "ae9ffbbe7d3b4f10aa28c43713059046": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "a0c1686dfae94710a21d5f49d56f5af5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "00e9cbd42fa9422ab8c99f4596f5b8a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "eaafce605a844b378df4911e61553fdb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "53d43df9b742499c95db87975f4a2295": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_d27c317dbd314034bfbd212d815dda82",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_ad51f9664f034d49a18d6790ede25317",
       "IPY_MODEL_616312f74242472587caf28b83897740"
      ]
     }
    },
    "d27c317dbd314034bfbd212d815dda82": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "ad51f9664f034d49a18d6790ede25317": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_502c09a0b5564bf7b55a3a7ce8abc0a1",
      "_dom_classes": [],
      "description": "Epoch 3 of 3: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 3,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 3,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_72f96435798b430a8a48b5e77e1a31fd"
     }
    },
    "616312f74242472587caf28b83897740": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_fd6e6e366280474594d37a4b639d2b9b",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "â€‹",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 3/3 [1:11:25&lt;00:00, 1428.66s/it]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_76ebf55da62a4d009907c36583e54854"
     }
    },
    "502c09a0b5564bf7b55a3a7ce8abc0a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "72f96435798b430a8a48b5e77e1a31fd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "fd6e6e366280474594d37a4b639d2b9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "76ebf55da62a4d009907c36583e54854": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "fad783d5155d40d8a2615d2c3e2f0671": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_e55317524081456a89f0fc9a1a9cf8c5",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_ded8bc0ea3d84cac8b2ef12e765afa0b",
       "IPY_MODEL_a191f5a32f5a4c25820d3a168baee659"
      ]
     }
    },
    "e55317524081456a89f0fc9a1a9cf8c5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "ded8bc0ea3d84cac8b2ef12e765afa0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_6d813661f4134247afa96a17600ab4c4",
      "_dom_classes": [],
      "description": "Running Epoch 0: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 2589,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 2589,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_0f377f45c0e8496683c1a9b35a2aa5b7"
     }
    },
    "a191f5a32f5a4c25820d3a168baee659": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_3ac11681d19645358d203b36fe2c49b8",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "â€‹",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 2589/2589 [1:11:25&lt;00:00,  1.66s/it]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_d5ce7cbf304649ac8863b4ac62279c3a"
     }
    },
    "6d813661f4134247afa96a17600ab4c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "0f377f45c0e8496683c1a9b35a2aa5b7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "3ac11681d19645358d203b36fe2c49b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "d5ce7cbf304649ac8863b4ac62279c3a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "67562766a9d54df88df7a6054c6c8e21": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_a0c211973c6e44cf89b110da90008e27",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_d71b7d9581dd4a26978fd81d48b17d0f",
       "IPY_MODEL_0ec49a36d2c64ebea811c497901d3213"
      ]
     }
    },
    "a0c211973c6e44cf89b110da90008e27": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "d71b7d9581dd4a26978fd81d48b17d0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_438a05999c184781a26466373491a2ed",
      "_dom_classes": [],
      "description": "Running Epoch 1: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 2589,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 2589,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_f88db0f3657f410891ae5ef6b3a1552d"
     }
    },
    "0ec49a36d2c64ebea811c497901d3213": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_98f098c661e54e21872886a3cc8d70e3",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "â€‹",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 2589/2589 [48:01&lt;00:00,  1.11s/it]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_5128dc9f677f4ad5b795d0afc4bff55c"
     }
    },
    "438a05999c184781a26466373491a2ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "f88db0f3657f410891ae5ef6b3a1552d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "98f098c661e54e21872886a3cc8d70e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "5128dc9f677f4ad5b795d0afc4bff55c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "5dbfd446c379451780009b8f143b6047": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_2d50eb838ff24726985edd208961b93c",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_37eb915a80a54d15913d28f7ed61235c",
       "IPY_MODEL_2ad0e76560b74fab825a68639890012c"
      ]
     }
    },
    "2d50eb838ff24726985edd208961b93c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "37eb915a80a54d15913d28f7ed61235c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_7632297b165f40beb5d0857dd8045b67",
      "_dom_classes": [],
      "description": "Running Epoch 2: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 2589,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 2589,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_18291f91d7c44753901bf3c17d523a19"
     }
    },
    "2ad0e76560b74fab825a68639890012c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_54714ba2b50a482aaa96849bfa7785c2",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "â€‹",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 2589/2589 [24:36&lt;00:00,  1.75it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_248e8b6ac3e049daba8b0bb1265f468e"
     }
    },
    "7632297b165f40beb5d0857dd8045b67": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "18291f91d7c44753901bf3c17d523a19": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "54714ba2b50a482aaa96849bfa7785c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "248e8b6ac3e049daba8b0bb1265f468e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "27857b2e9871485eb9d0978faf23c866": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_45e60f62ffbb425896008eee6d015161",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_052327fd6c624c3abdd89b393e0d187a",
       "IPY_MODEL_fb6b2483b7724c32882ab3ae9853eb0d"
      ]
     }
    },
    "45e60f62ffbb425896008eee6d015161": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "052327fd6c624c3abdd89b393e0d187a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_48dea92eda0c411699d04b64aef3d3eb",
      "_dom_classes": [],
      "description": "100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 2558,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 2558,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_e13eb1d43e5242f99fa29c0c16889de1"
     }
    },
    "fb6b2483b7724c32882ab3ae9853eb0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_07d9d084bb8d407cb8f8ddd4cfa96528",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "â€‹",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 2558/2558 [01:07&lt;00:00, 38.17it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_c185a0bc13244499a10b7aa52642f797"
     }
    },
    "48dea92eda0c411699d04b64aef3d3eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "e13eb1d43e5242f99fa29c0c16889de1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "07d9d084bb8d407cb8f8ddd4cfa96528": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "c185a0bc13244499a10b7aa52642f797": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "3aaf0fee85f4467a93d37fed31f56a66": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_252274bcfb8847c9a881d3c46da3fd94",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_743a423f83004eccb5a713545bfc2eca",
       "IPY_MODEL_f1222464f0f744dea491133def101f85"
      ]
     }
    },
    "252274bcfb8847c9a881d3c46da3fd94": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "743a423f83004eccb5a713545bfc2eca": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_49f279f8a8ba4d09baaab01bb7f1ba7c",
      "_dom_classes": [],
      "description": "Running Evaluation: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 320,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 320,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_027780d27f204cda8348e1527fdaaa02"
     }
    },
    "f1222464f0f744dea491133def101f85": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_7fe5edeb3b75488aab28385875d71d36",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "â€‹",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 320/320 [01:01&lt;00:00,  5.22it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_34674ad05d3f442f8dfc70918952edbc"
     }
    },
    "49f279f8a8ba4d09baaab01bb7f1ba7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "027780d27f204cda8348e1527fdaaa02": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "7fe5edeb3b75488aab28385875d71d36": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "34674ad05d3f442f8dfc70918952edbc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "72f233123c1a40c68d42348f0fa991f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_748e60c78d8a4d75a6c9fbfadb4d1a55",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_db374a6d0f2c4259964bb407aa1d3e8f",
       "IPY_MODEL_a2ae6b43c6984e908449d038ff95d142"
      ]
     }
    },
    "748e60c78d8a4d75a6c9fbfadb4d1a55": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "db374a6d0f2c4259964bb407aa1d3e8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_3d93f3c927cb468981082bebea2a05a5",
      "_dom_classes": [],
      "description": "100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 2558,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 2558,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_d6c7549b582f41c9983281b55b83b335"
     }
    },
    "a2ae6b43c6984e908449d038ff95d142": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_c10c4f05008944ca87d7a87828ede99e",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "â€‹",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 2558/2558 [00:01&lt;00:00, 2088.15it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_e428be8baa334b24a7d82fc9f574ea76"
     }
    },
    "3d93f3c927cb468981082bebea2a05a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "d6c7549b582f41c9983281b55b83b335": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "c10c4f05008944ca87d7a87828ede99e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "e428be8baa334b24a7d82fc9f574ea76": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "a1b9ef62a27047819c18c6a7b2402354": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_d738e7d64eeb48c5ae86a3ce1de2b292",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_ba18ce88f86f48d2ae925a576108e52e",
       "IPY_MODEL_88ec80ef321d481d871baf3ff50aab2f"
      ]
     }
    },
    "d738e7d64eeb48c5ae86a3ce1de2b292": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "ba18ce88f86f48d2ae925a576108e52e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_2c69b8d61ebe44e985d8dd5afb9197aa",
      "_dom_classes": [],
      "description": "100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 320,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 320,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_f7afed5a93f54a9d9328c9d66e44a2f6"
     }
    },
    "88ec80ef321d481d871baf3ff50aab2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_709296532d064c37b995fa04eea6b80a",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "â€‹",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 320/320 [01:01&lt;00:00,  5.24it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_052bfb48725c44dbad7422c688205d4b"
     }
    },
    "2c69b8d61ebe44e985d8dd5afb9197aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "f7afed5a93f54a9d9328c9d66e44a2f6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "709296532d064c37b995fa04eea6b80a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "052bfb48725c44dbad7422c688205d4b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "YDHCjaH5QrDk",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595436309101,
     "user_tz": -120,
     "elapsed": 27762,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "afc63d79-3f1a-4a46-9fb5-3bcee0e0b570"
   },
   "source": [
    "#%tensorflow_version 2.x\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/', force_remount=True)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
      "Mounted at /content/drive/\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_t6gg1ZLRYxS",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import sys\n",
    "projectDir = \"/content/drive/My Drive/code/git/tweepfake_deepfake_text_detection\"\n",
    "sys.path.insert(0, projectDir)\n",
    "\n",
    "random_state = 523 # Fixed seed for replicability of randomic operations.\n",
    "resultsDir = projectDir+\"/data/results\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DuMYSMSjTjdr",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595436309103,
     "user_tz": -120,
     "elapsed": 27752,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "3c6c1019-3c3d-405c-9d3d-41430e108632"
   },
   "source": [
    "%%writefile setup.sh\n",
    "\n",
    "export CUDA_HOME=/usr/local/cuda-10.1\n",
    "git clone https://github.com/NVIDIA/apex\n",
    "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Writing setup.sh\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sW5qeRXxVQMB",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595436856720,
     "user_tz": -120,
     "elapsed": 575362,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "a1e45297-8e54-40af-fd6c-6c5e28294487"
   },
   "source": [
    "!sh setup.sh"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Cloning into 'apex'...\n",
      "remote: Enumerating objects: 14, done.\u001B[K\n",
      "remote: Counting objects: 100% (14/14), done.\u001B[K\n",
      "remote: Compressing objects: 100% (14/14), done.\u001B[K\n",
      "remote: Total 7367 (delta 3), reused 0 (delta 0), pack-reused 7353\u001B[K\n",
      "Receiving objects: 100% (7367/7367), 13.89 MiB | 12.96 MiB/s, done.\n",
      "Resolving deltas: 100% (4974/4974), done.\n",
      "/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
      "  cmdoptions.check_install_build_global(options)\n",
      "Created temporary directory: /tmp/pip-ephem-wheel-cache-7hv0pjtc\n",
      "Created temporary directory: /tmp/pip-req-tracker-7sxrwyld\n",
      "Created requirements tracker '/tmp/pip-req-tracker-7sxrwyld'\n",
      "Created temporary directory: /tmp/pip-install-069661w0\n",
      "Processing ./apex\n",
      "  Created temporary directory: /tmp/pip-req-build-ng7xpxj1\n",
      "  Added file:///content/apex to build tracker '/tmp/pip-req-tracker-7sxrwyld'\n",
      "    Running setup.py (path:/tmp/pip-req-build-ng7xpxj1/setup.py) egg_info for package from file:///content/apex\n",
      "    Running command python setup.py egg_info\n",
      "\n",
      "\n",
      "    torch.__version__  = 1.5.1+cu101\n",
      "\n",
      "\n",
      "    running egg_info\n",
      "    creating /tmp/pip-req-build-ng7xpxj1/pip-egg-info/apex.egg-info\n",
      "    writing /tmp/pip-req-build-ng7xpxj1/pip-egg-info/apex.egg-info/PKG-INFO\n",
      "    writing dependency_links to /tmp/pip-req-build-ng7xpxj1/pip-egg-info/apex.egg-info/dependency_links.txt\n",
      "    writing top-level names to /tmp/pip-req-build-ng7xpxj1/pip-egg-info/apex.egg-info/top_level.txt\n",
      "    writing manifest file '/tmp/pip-req-build-ng7xpxj1/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
      "    writing manifest file '/tmp/pip-req-build-ng7xpxj1/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
      "    /tmp/pip-req-build-ng7xpxj1/setup.py:51: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
      "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
      "  Source in /tmp/pip-req-build-ng7xpxj1 has version 0.1, which satisfies requirement apex==0.1 from file:///content/apex\n",
      "  Removed apex==0.1 from file:///content/apex from build tracker '/tmp/pip-req-tracker-7sxrwyld'\n",
      "Skipping wheel build for apex, due to binaries being disabled for it.\n",
      "Installing collected packages: apex\n",
      "  Created temporary directory: /tmp/pip-record-z14o6ctr\n",
      "    Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-ng7xpxj1/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-ng7xpxj1/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-z14o6ctr/install-record.txt --single-version-externally-managed --compile\n",
      "\n",
      "\n",
      "    torch.__version__  = 1.5.1+cu101\n",
      "\n",
      "\n",
      "    /tmp/pip-req-build-ng7xpxj1/setup.py:51: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
      "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
      "\n",
      "    Compiling cuda extensions with\n",
      "    nvcc: NVIDIA (R) Cuda compiler driver\n",
      "    Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "    Built on Sun_Jul_28_19:07:16_PDT_2019\n",
      "    Cuda compilation tools, release 10.1, V10.1.243\n",
      "    from /usr/local/cuda-10.1/bin\n",
      "\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build/lib.linux-x86_64-3.6\n",
      "    creating build/lib.linux-x86_64-3.6/apex\n",
      "    copying apex/__init__.py -> build/lib.linux-x86_64-3.6/apex\n",
      "    creating build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "    copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "    copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "    copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "    creating build/lib.linux-x86_64-3.6/apex/contrib\n",
      "    copying apex/contrib/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib\n",
      "    creating build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
      "    copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
      "    copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
      "    creating build/lib.linux-x86_64-3.6/apex/normalization\n",
      "    copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
      "    copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
      "    creating build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    creating build/lib.linux-x86_64-3.6/apex/mlp\n",
      "    copying apex/mlp/mlp.py -> build/lib.linux-x86_64-3.6/apex/mlp\n",
      "    copying apex/mlp/__init__.py -> build/lib.linux-x86_64-3.6/apex/mlp\n",
      "    creating build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    creating build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/handle.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/amp.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/utils.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/opt.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    creating build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    copying apex/RNN/models.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    creating build/lib.linux-x86_64-3.6/apex/pyprof\n",
      "    copying apex/pyprof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof\n",
      "    creating build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/fused_adagrad.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    creating build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
      "    copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
      "    copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
      "    creating build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
      "    copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
      "    copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
      "    creating build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
      "    creating build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
      "    copying apex/contrib/sparsity/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
      "    copying apex/contrib/sparsity/asp.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
      "    copying apex/contrib/sparsity/sparse_masklib.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
      "    creating build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
      "    creating build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    creating build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
      "    copying apex/pyprof/nvtx/nvmarker.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
      "    copying apex/pyprof/nvtx/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
      "    creating build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
      "    copying apex/pyprof/parse/kernel.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
      "    copying apex/pyprof/parse/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
      "    copying apex/pyprof/parse/db.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
      "    copying apex/pyprof/parse/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
      "    copying apex/pyprof/parse/nvvp.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
      "    copying apex/pyprof/parse/parse.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
      "    creating build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/optim.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/embedding.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/usage.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/output.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/data.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/misc.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/pointwise.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/linear.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/pooling.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/conv.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/randomSample.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/loss.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/base.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/reduction.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/blas.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/softmax.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/convert.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/activation.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/recurrentCell.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/dropout.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/utility.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/normalization.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/prof.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    running build_ext\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/utils/cpp_extension.py:305: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "      warnings.warn(msg.format('we could not find ninja.'))\n",
      "    building 'apex_C' extension\n",
      "    creating build/temp.linux-x86_64-3.6\n",
      "    creating build/temp.linux-x86_64-3.6/csrc\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "    In file included from csrc/flatten_unflatten.cpp:2:0:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h: In member function â€˜at::DeprecatedTypeProperties& torch::utils::TensorGroup::type()â€™:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h:36:28: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "         return tensors[0].type();\n",
      "                                ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/flatten_unflatten.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so\n",
      "    building 'amp_C' extension\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_sgd_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_l2norm_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_1.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_2.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_adam.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_adagrad.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adagrad.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_novograd.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adagrad.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda-10.1/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so\n",
      "    building 'syncbn' extension\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/syncbn.cpp -o build/temp.linux-x86_64-3.6/csrc/syncbn.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/welford.cu -o build/temp.linux-x86_64-3.6/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/syncbn.o build/temp.linux-x86_64-3.6/csrc/welford.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda-10.1/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so\n",
      "    building 'fused_layer_norm_cuda' extension\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp: In function â€˜std::vector<at::Tensor> layer_norm(at::Tensor, c10::IntArrayRef, double)â€™:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:129:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
      "       CHECK_INPUT(input);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp: In function â€˜std::vector<at::Tensor> layer_norm_affine(at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)â€™:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:149:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
      "       CHECK_INPUT(input);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:150:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
      "       CHECK_INPUT(gamma);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:151:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
      "       CHECK_INPUT(beta);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp: In function â€˜at::Tensor layer_norm_gradient(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, double)â€™:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:193:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
      "       CHECK_INPUT(dout);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:194:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
      "       CHECK_INPUT(mean);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:195:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
      "       CHECK_INPUT(invvar);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:196:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
      "       CHECK_INPUT(input);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp: In function â€˜std::vector<at::Tensor> layer_norm_gradient_affine(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)â€™:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:218:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
      "       CHECK_INPUT(dout);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:219:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
      "       CHECK_INPUT(mean);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:220:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
      "       CHECK_INPUT(invvar);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:221:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
      "       CHECK_INPUT(input);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:222:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
      "       CHECK_INPUT(gamma);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    csrc/layer_norm_cuda.cpp:117:42: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                                              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro â€˜C10_UNLIKELYâ€™\n",
      "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
      "                                                                     ^~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro â€˜C10_UNLIKELY_OR_CONSTâ€™\n",
      "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro â€˜TORCH_CHECK_WITHâ€™\n",
      "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
      "                                    ^~~~~~~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro â€˜TORCH_CHECKâ€™\n",
      "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro â€˜CHECK_CUDAâ€™\n",
      "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
      "                            ^~~~~~~~~~\n",
      "    csrc/layer_norm_cuda.cpp:223:3: note: in expansion of macro â€˜CHECK_INPUTâ€™\n",
      "       CHECK_INPUT(beta);\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/layer_norm_cuda.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda-10.1/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so\n",
      "    building 'mlp_cuda' extension\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/mlp.cpp -o build/temp.linux-x86_64-3.6/csrc/mlp.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "    csrc/mlp.cpp: In function â€˜std::vector<at::Tensor> mlp_forward(int, int, std::vector<at::Tensor>)â€™:\n",
      "    csrc/mlp.cpp:56:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "       for (int i = 0; i < num_layers; i++) {\n",
      "                       ~~^~~~~~~~~~~~\n",
      "    csrc/mlp.cpp:64:77: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "       auto out = at::empty({batch_size, output_features.back()}, inputs[0].type());\n",
      "                                                                                 ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    csrc/mlp.cpp:65:67: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n",
      "                                                                       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    csrc/mlp.cpp:65:68: warning: narrowing conversion of â€˜reserved_sizeâ€™ from â€˜long unsigned intâ€™ to â€˜long intâ€™ inside { } [-Wnarrowing]\n",
      "       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n",
      "                                                                        ^\n",
      "    csrc/mlp.cpp:65:68: warning: narrowing conversion of â€˜reserved_sizeâ€™ from â€˜long unsigned intâ€™ to â€˜long intâ€™ inside { } [-Wnarrowing]\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    csrc/mlp.cpp: In lambda function:\n",
      "    csrc/mlp.cpp:67:54: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "                                                          ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:129:28: note: in definition of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
      "         const auto& the_type = TYPE;                                             \\\n",
      "                                ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:131:56: warning: â€˜c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)â€™ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
      "         at::ScalarType _st = ::detail::scalar_type(the_type);                    \\\n",
      "                                                            ^\n",
      "    csrc/mlp.cpp:67:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "       ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:46:23: note: declared here\n",
      "     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp: In lambda function:\n",
      "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < num_layers; i++) {\n",
      "                         ~~^~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:67:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:76:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]\n",
      "         auto result = mlp_fp<scalar_t>(\n",
      "              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:67:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp: In lambda function:\n",
      "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < num_layers; i++) {\n",
      "                         ~~^~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:67:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:76:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]\n",
      "         auto result = mlp_fp<scalar_t>(\n",
      "              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:67:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp: In lambda function:\n",
      "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < num_layers; i++) {\n",
      "                         ~~^~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:67:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:76:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]\n",
      "         auto result = mlp_fp<scalar_t>(\n",
      "              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:67:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp: In function â€˜std::vector<at::Tensor> mlp_backward(int, int, at::Tensor, std::vector<at::Tensor>, std::vector<at::Tensor>)â€™:\n",
      "    csrc/mlp.cpp:113:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "       for (int i = 0; i < num_layers; i++) {\n",
      "                       ~~^~~~~~~~~~~~\n",
      "    csrc/mlp.cpp:119:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "       for (int i = 0; i < inputs.size(); i++) {\n",
      "                       ~~^~~~~~~~~~~~~~~\n",
      "    csrc/mlp.cpp:120:67: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "         outputs.push_back(at::empty(inputs[i].sizes(), inputs[i].type()));  // clone for testing now\n",
      "                                                                       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    csrc/mlp.cpp: In lambda function:\n",
      "    csrc/mlp.cpp:123:54: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "                                                          ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:129:28: note: in definition of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
      "         const auto& the_type = TYPE;                                             \\\n",
      "                                ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:131:56: warning: â€˜c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)â€™ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
      "         at::ScalarType _st = ::detail::scalar_type(the_type);                    \\\n",
      "                                                            ^\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:46:23: note: declared here\n",
      "     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
      "                           ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp: In lambda function:\n",
      "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < num_layers; i++) {\n",
      "                         ~~^~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < inputs.size(); i++) {\n",
      "                         ~~^~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:137:80: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                                                                    ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    csrc/mlp.cpp:137:44: warning: narrowing conversion of â€˜(work_size / sizeof (scalar_t))â€™ from â€˜long unsigned intâ€™ to â€˜long intâ€™ inside { } [-Wnarrowing]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                      ~~~~~~~~~~^~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:137:44: warning: narrowing conversion of â€˜(work_size / sizeof (scalar_t))â€™ from â€˜long unsigned intâ€™ to â€˜long intâ€™ inside { } [-Wnarrowing]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                      ~~~~~~~~~~^~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:139:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]\n",
      "         auto result = mlp_bp<scalar_t>(\n",
      "              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp: In lambda function:\n",
      "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < num_layers; i++) {\n",
      "                         ~~^~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < inputs.size(); i++) {\n",
      "                         ~~^~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:137:80: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                                                                    ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    csrc/mlp.cpp:137:44: warning: narrowing conversion of â€˜(work_size / sizeof (scalar_t))â€™ from â€˜long unsigned intâ€™ to â€˜long intâ€™ inside { } [-Wnarrowing]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                      ~~~~~~~~~~^~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:137:44: warning: narrowing conversion of â€˜(work_size / sizeof (scalar_t))â€™ from â€˜long unsigned intâ€™ to â€˜long intâ€™ inside { } [-Wnarrowing]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                      ~~~~~~~~~~^~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:139:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]\n",
      "         auto result = mlp_bp<scalar_t>(\n",
      "              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp: In lambda function:\n",
      "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < num_layers; i++) {\n",
      "                         ~~^~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
      "         for (int i = 0; i < inputs.size(); i++) {\n",
      "                         ~~^~~~~~~~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:137:80: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                                                                    ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:11:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
      "       DeprecatedTypeProperties & type() const {\n",
      "                                  ^~~~\n",
      "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
      "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
      "                     from csrc/mlp.cpp:1:\n",
      "    csrc/mlp.cpp:137:44: warning: narrowing conversion of â€˜(work_size / sizeof (scalar_t))â€™ from â€˜long unsigned intâ€™ to â€˜long intâ€™ inside { } [-Wnarrowing]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                      ~~~~~~~~~~^~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:137:44: warning: narrowing conversion of â€˜(work_size / sizeof (scalar_t))â€™ from â€˜long unsigned intâ€™ to â€˜long intâ€™ inside { } [-Wnarrowing]\n",
      "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
      "                                      ~~~~~~~~~~^~~~~~~~~\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    csrc/mlp.cpp:139:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]\n",
      "         auto result = mlp_bp<scalar_t>(\n",
      "              ^\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
      "         return __VA_ARGS__();                          \\\n",
      "                ^~~~~~~~~~~\n",
      "    csrc/mlp.cpp:123:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
      "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
      "       ^\n",
      "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/mlp_cuda.cu -o build/temp.linux-x86_64-3.6/csrc/mlp_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(14): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(18): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(23): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(100): warning: attribute \"__visibility__\" does not apply here\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(115): warning: attribute \"__visibility__\" does not apply here\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(14): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(18): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(23): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(100): warning: attribute \"__visibility__\" does not apply here\n",
      "\n",
      "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(115): warning: attribute \"__visibility__\" does not apply here\n",
      "\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/mlp.o build/temp.linux-x86_64-3.6/csrc/mlp_cuda.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda-10.1/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/mlp_cuda.cpython-36m-x86_64-linux-gnu.so\n",
      "    running install_lib\n",
      "    copying build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    copying build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/weight_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/reparameterization.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/softmax_xentropy.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/batch_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/asp.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/sparse_masklib.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam_v2.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam_v3.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
      "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
      "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/multi_tensor_apply.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/normalization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/normalization/fused_layer_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/LARC.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/multiproc.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/distributed.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/mlp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/mlp/mlp.py -> /usr/local/lib/python3.6/dist-packages/apex/mlp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/mlp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/mlp\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16util.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/loss_scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    copying build/lib.linux-x86_64-3.6/apex/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/_amp_state.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/__version__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/_process_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/handle.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/tensor_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/functional_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/torch_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/wrap.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/_initialize.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/amp.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/rnn_compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/utils.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/frontend.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/opt.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    copying build/lib.linux-x86_64-3.6/apex/RNN/models.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    copying build/lib.linux-x86_64-3.6/apex/RNN/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    copying build/lib.linux-x86_64-3.6/apex/RNN/RNNBackend.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    copying build/lib.linux-x86_64-3.6/apex/RNN/cells.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/nvmarker.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/db.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/nvvp.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/parse.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/optim.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/embedding.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/usage.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/output.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/data.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/misc.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pointwise.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/linear.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pooling.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/conv.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/index_slice_join_mutate.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/randomSample.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/loss.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/base.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/reduction.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/blas.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/softmax.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/convert.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/activation.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/recurrentCell.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/dropout.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/utility.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/normalization.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/prof.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_novograd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adagrad.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    copying build/lib.linux-x86_64-3.6/mlp_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    copying build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/weight_norm.py to weight_norm.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/reparameterization.py to reparameterization.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py to fast_encdec_multihead_attn_norm_add_func.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/self_multihead_attn.py to self_multihead_attn.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/self_multihead_attn_func.py to self_multihead_attn_func.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py to fast_encdec_multihead_attn_func.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py to fast_self_multihead_attn_func.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py to fast_self_multihead_attn_norm_add_func.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn_func.py to encdec_multihead_attn_func.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/mask_softmax_dropout_func.py to mask_softmax_dropout_func.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn.py to encdec_multihead_attn.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/asp.py to asp.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/sparse_masklib.py to sparse_masklib.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v2.py to distributed_fused_adam_v2.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py to distributed_fused_lamb.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam.py to distributed_fused_adam.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v3.py to distributed_fused_adam_v3.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/LARC.py to LARC.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/multiproc.py to multiproc.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/distributed.py to distributed.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/mlp/mlp.py to mlp.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/mlp/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16util.py to fp16util.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_amp_state.py to _amp_state.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/compat.py to compat.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__version__.py to __version__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_process_optimizer.py to _process_optimizer.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/handle.py to handle.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/wrap.py to wrap.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_initialize.py to _initialize.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/amp.py to amp.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/rnn_compat.py to rnn_compat.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/utils.py to utils.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/frontend.py to frontend.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/scaler.py to scaler.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/opt.py to opt.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/models.py to models.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/RNNBackend.py to RNNBackend.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/cells.py to cells.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/nvmarker.py to nvmarker.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/kernel.py to kernel.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/db.py to db.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__main__.py to __main__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/nvvp.py to nvvp.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/parse.py to parse.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/optim.py to optim.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/embedding.py to embedding.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/usage.py to usage.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/output.py to output.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/data.py to data.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/misc.py to misc.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pointwise.py to pointwise.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/linear.py to linear.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pooling.py to pooling.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/conv.py to conv.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/index_slice_join_mutate.py to index_slice_join_mutate.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/randomSample.py to randomSample.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/loss.py to loss.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/base.py to base.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/reduction.py to reduction.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/blas.py to blas.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/softmax.py to softmax.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/convert.py to convert.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/activation.py to activation.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__main__.py to __main__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/recurrentCell.py to recurrentCell.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/dropout.py to dropout.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/utility.py to utility.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/normalization.py to normalization.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/prof.py to prof.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_novograd.py to fused_novograd.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adagrad.py to fused_adagrad.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
      "    running install_egg_info\n",
      "    running egg_info\n",
      "    creating apex.egg-info\n",
      "    writing apex.egg-info/PKG-INFO\n",
      "    writing dependency_links to apex.egg-info/dependency_links.txt\n",
      "    writing top-level names to apex.egg-info/top_level.txt\n",
      "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "    Copying apex.egg-info to /usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6.egg-info\n",
      "    running install_scripts\n",
      "    writing list of installed files to '/tmp/pip-record-z14o6ctr/install-record.txt'\n",
      "    Running setup.py install for apex ... \u001B[?25l\u001B[?25hdone\n",
      "  Removing source in /tmp/pip-req-build-ng7xpxj1\n",
      "Successfully installed apex-0.1\n",
      "Cleaning up...\n",
      "Removed build tracker '/tmp/pip-req-tracker-7sxrwyld'\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XqnRBYPkcx_g",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "V3qW3001RonB",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595436872972,
     "user_tz": -120,
     "elapsed": 591604,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "db2e06ed-234c-4e17-f6a0-55e171aa9255"
   },
   "source": [
    "!pip install pandas transformers simpletransformers==0.41 amp"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.5)\n",
      "Collecting transformers\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 778kB 6.0MB/s \n",
      "\u001B[?25hCollecting simpletransformers==0.41\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/99/0d/4e3d32c543e340a52dfbf908b1cc2dea16b605ba0c67a6fb39654c73d555/simpletransformers-0.41.0-py3-none-any.whl (191kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 194kB 18.4MB/s \n",
      "\u001B[?25hCollecting amp\n",
      "  Downloading https://files.pythonhosted.org/packages/1a/cb/9bab4fdd2d8f1d2aacc7cf2d20ad84fa4196d276b3a494960787453b31e9/AMP-1.1.4.tar.gz\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Collecting tokenizers==0.8.1.rc1\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0MB 18.2MB/s \n",
      "\u001B[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Collecting sentencepiece!=0.1.92\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 38.6MB/s \n",
      "\u001B[?25hCollecting sacremoses\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 44.8MB/s \n",
      "\u001B[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from simpletransformers==0.41) (1.4.1)\n",
      "Collecting seqeval\n",
      "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from simpletransformers==0.41) (0.22.2.post1)\n",
      "Collecting tensorboardx\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 317kB 36.8MB/s \n",
      "\u001B[?25hRequirement already satisfied: Django>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from amp) (3.0.8)\n",
      "Collecting caldav==0.1.4\n",
      "  Downloading https://files.pythonhosted.org/packages/53/c6/181e4dbe8ee69e1161687991262d79b070282c93833298be2cc8ca1f6ade/caldav-0.1.4.tar.gz\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.15.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
      "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval->simpletransformers==0.41) (2.3.1)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardx->simpletransformers==0.41) (3.12.2)\n",
      "Requirement already satisfied: sqlparse>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from Django>=1.1.1->amp) (0.3.1)\n",
      "Requirement already satisfied: asgiref~=3.2 in /usr/local/lib/python3.6/dist-packages (from Django>=1.1.1->amp) (3.2.10)\n",
      "Collecting vobject\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/da/ce/27c48c0e39cc69ffe7f6e3751734f6073539bf18a0cfe564e973a3709a52/vobject-0.9.6.1.tar.gz (58kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 7.4MB/s \n",
      "\u001B[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from caldav==0.1.4->amp) (4.2.6)\n",
      "Collecting nose\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
      "\u001B[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163kB 38.6MB/s \n",
      "\u001B[?25hRequirement already satisfied: coverage in /usr/local/lib/python3.6/dist-packages (from caldav==0.1.4->amp) (3.7.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->simpletransformers==0.41) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->simpletransformers==0.41) (3.13)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->simpletransformers==0.41) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->simpletransformers==0.41) (1.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardx->simpletransformers==0.41) (49.1.0)\n",
      "Building wheels for collected packages: amp, sacremoses, seqeval, caldav, vobject\n",
      "  Building wheel for amp (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for amp: filename=AMP-1.1.4-cp36-none-any.whl size=9417 sha256=c9557a8794a524b04d45830a2e9cde203533a9f3689302bb302fb3b9f301768f\n",
      "  Stored in directory: /root/.cache/pip/wheels/c4/9c/a0/acaeece5c47a0249f6152849c2e694fee9afbb43a8864b9128\n",
      "  Building wheel for sacremoses (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=5fed0c3a584a937fc040af7bd190ca833639a3ee5b6473b7d3235467f6ab2846\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "  Building wheel for seqeval (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=238db8f4c59b377b3e29588f900f9d6cd1799391d8b2666276fc0fad1e6260db\n",
      "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
      "  Building wheel for caldav (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for caldav: filename=caldav-0.1.4-cp36-none-any.whl size=12305 sha256=93660fa19759e893ef007b23571607d7bf816dc2cbd9d532ae62a5294815f6ce\n",
      "  Stored in directory: /root/.cache/pip/wheels/e7/65/04/138802f7957e4ee778dde8fb03eb406fcd2f15e12baee1ef66\n",
      "  Building wheel for vobject (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for vobject: filename=vobject-0.9.6.1-cp36-none-any.whl size=47664 sha256=653188b4aa84d3f1e92a2cc75ac60144484f4dbe221a930a01494ea22242f179\n",
      "  Stored in directory: /root/.cache/pip/wheels/bb/4b/53/aaf3243d7bd9bcf636b1a17dee2f075cecc8581a387548b5a8\n",
      "Successfully built amp sacremoses seqeval caldav vobject\n",
      "\u001B[31mERROR: simpletransformers 0.41.0 has requirement tokenizers<=0.7, but you'll have tokenizers 0.8.1rc1 which is incompatible.\u001B[0m\n",
      "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers, seqeval, tensorboardx, simpletransformers, vobject, nose, caldav, amp\n",
      "Successfully installed amp-1.1.4 caldav-0.1.4 nose-1.3.7 sacremoses-0.0.43 sentencepiece-0.1.91 seqeval-0.0.12 simpletransformers-0.41.0 tensorboardx-2.1 tokenizers-0.8.1rc1 transformers-3.0.2 vobject-0.9.6.1\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lLsNhiofRy5r",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from DataHandler import DataHandler\n",
    "\n",
    "csvTrainDataset = projectDir+\"/data/splits/train.csv\"\n",
    "csvValDataset = projectDir+\"/data/splits/validation.csv\"\n",
    "csvTestDataset = projectDir+\"/data/splits/test.csv\"\n",
    "\n",
    "bertDir = projectDir+\"/data/encoded/bert\"\n",
    "dh = DataHandler()\n",
    "dfTrain = dh.readCSVData(csvTrainDataset)\n",
    "dfVal = dh.readCSVData(csvValDataset)\n",
    "dfTest = dh.readCSVData(csvTestDataset)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mBCDg773SZKW",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595436877731,
     "user_tz": -120,
     "elapsed": 596354,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "116ddf88-334f-47f6-af93-960b9c1b72e4"
   },
   "source": [
    "dfTrain"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_prog</th>\n",
       "      <th>user_id</th>\n",
       "      <th>status_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>display_text_width</th>\n",
       "      <th>reply_to_status_id</th>\n",
       "      <th>reply_to_user_id</th>\n",
       "      <th>reply_to_screen_name</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>symbols</th>\n",
       "      <th>urls_url</th>\n",
       "      <th>urls_t.co</th>\n",
       "      <th>urls_expanded_url</th>\n",
       "      <th>media_url</th>\n",
       "      <th>media_t.co</th>\n",
       "      <th>media_expanded_url</th>\n",
       "      <th>media_type</th>\n",
       "      <th>ext_media_url</th>\n",
       "      <th>ext_media_t.co</th>\n",
       "      <th>ext_media_expanded_url</th>\n",
       "      <th>ext_media_type</th>\n",
       "      <th>mentions_user_id</th>\n",
       "      <th>mentions_screen_name</th>\n",
       "      <th>lang</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_text</th>\n",
       "      <th>quoted_created_at</th>\n",
       "      <th>quoted_source</th>\n",
       "      <th>quoted_favorite_count</th>\n",
       "      <th>quoted_retweet_count</th>\n",
       "      <th>quoted_user_id</th>\n",
       "      <th>...</th>\n",
       "      <th>place_url</th>\n",
       "      <th>place_name</th>\n",
       "      <th>place_full_name</th>\n",
       "      <th>place_type</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "      <th>geo_coords</th>\n",
       "      <th>coords_coords</th>\n",
       "      <th>bbox_coords</th>\n",
       "      <th>status_url</th>\n",
       "      <th>name</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>protected</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>account_created_at</th>\n",
       "      <th>verified</th>\n",
       "      <th>profile_url</th>\n",
       "      <th>profile_expanded_url</th>\n",
       "      <th>account_lang</th>\n",
       "      <th>profile_banner_url</th>\n",
       "      <th>profile_background_url</th>\n",
       "      <th>profile_image_url</th>\n",
       "      <th>created</th>\n",
       "      <th>data.tweet</th>\n",
       "      <th>ora.tweet</th>\n",
       "      <th>tweet_type</th>\n",
       "      <th>mention_TF</th>\n",
       "      <th>hashtag_TF</th>\n",
       "      <th>url_TF</th>\n",
       "      <th>n.words</th>\n",
       "      <th>punct</th>\n",
       "      <th>account.type</th>\n",
       "      <th>finetuning_source</th>\n",
       "      <th>class_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14692</td>\n",
       "      <td>x1110407881030017024</td>\n",
       "      <td>x1208265880146046976</td>\n",
       "      <td>2019-12-21 06:00:08</td>\n",
       "      <td>imranyebot</td>\n",
       "      <td>YEA now that note GOOD</td>\n",
       "      <td>imranye-twitter-bot</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA NA NA NA NA NA NA</td>\n",
       "      <td>https://twitter.com/imranyebot/status/12082658...</td>\n",
       "      <td>imranyebot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@imranye in robot form. tweets every hour gene...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7467</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-26 05:07:23</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1110408254...</td>\n",
       "      <td>2019-12-21 06:00:08</td>\n",
       "      <td>2019-12-21</td>\n",
       "      <td>06:00:08</td>\n",
       "      <td>tweet</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>imranye</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22336</td>\n",
       "      <td>x3171109449</td>\n",
       "      <td>x1091463908118941696</td>\n",
       "      <td>2019-02-01 22:30:48</td>\n",
       "      <td>zawvrk</td>\n",
       "      <td>Listen to This Charming Man by The Smiths  htt...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>soundcloud.com/thesmiths/thisâ€¦</td>\n",
       "      <td>https://t.co/r12OIXkfUO</td>\n",
       "      <td>https://soundcloud.com/thesmiths/this-charming...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA NA NA NA NA NA NA</td>\n",
       "      <td>https://twitter.com/zawvrk/status/109146390811...</td>\n",
       "      <td>zawar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gold experience</td>\n",
       "      <td>https://t.co/J60plTSsKt</td>\n",
       "      <td>False</td>\n",
       "      <td>558</td>\n",
       "      <td>274</td>\n",
       "      <td>8</td>\n",
       "      <td>12216</td>\n",
       "      <td>23633</td>\n",
       "      <td>2015-04-15 19:50:16</td>\n",
       "      <td>False</td>\n",
       "      <td>https://t.co/J60plTSsKt</td>\n",
       "      <td>https://www.instagram.com/zawvr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/31711094...</td>\n",
       "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1229957200...</td>\n",
       "      <td>2019-02-01 22:30:48</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>22:30:48</td>\n",
       "      <td>tweet</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>human</td>\n",
       "      <td>original</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24087</td>\n",
       "      <td>x1110686081341632512</td>\n",
       "      <td>x1199055191028293633</td>\n",
       "      <td>2019-11-25 20:00:09</td>\n",
       "      <td>zawarbot</td>\n",
       "      <td>wish i can i would be seeing other hoes on the...</td>\n",
       "      <td>zawar-twitter-bot</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA NA NA NA NA NA NA</td>\n",
       "      <td>https://twitter.com/zawarbot/status/1199055191...</td>\n",
       "      <td>zawarbot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Iâ€™m an AI Bot that tries to tweet like @zawvrk...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4054</td>\n",
       "      <td>9</td>\n",
       "      <td>2019-03-26 23:32:52</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1185589257...</td>\n",
       "      <td>2019-11-25 20:00:09</td>\n",
       "      <td>2019-11-25</td>\n",
       "      <td>20:00:09</td>\n",
       "      <td>tweet</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>bot</td>\n",
       "      <td>zawvrk</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7584</td>\n",
       "      <td>x1110307772783124480</td>\n",
       "      <td>x1214698264701722626</td>\n",
       "      <td>2020-01-08 00:00:08</td>\n",
       "      <td>ahadsheriffbot</td>\n",
       "      <td>The decade in the significantly easier schedul...</td>\n",
       "      <td>ahadsheriff-bot</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA NA NA NA NA NA NA</td>\n",
       "      <td>https://twitter.com/ahadsheriffbot/status/1214...</td>\n",
       "      <td>Robot Ahad Sheriff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@ahadsheriff in robot form. tweets every hour ...</td>\n",
       "      <td>https://t.co/2G243YsNOt</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7946</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-25 22:29:36</td>\n",
       "      <td>False</td>\n",
       "      <td>https://t.co/2G243YsNOt</td>\n",
       "      <td>https://ahadsheriff.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1110311752...</td>\n",
       "      <td>2020-01-08 00:00:08</td>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>00:00:08</td>\n",
       "      <td>tweet</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>bot</td>\n",
       "      <td>ahadsheriff</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19654</td>\n",
       "      <td>x979586167405363200</td>\n",
       "      <td>x1209229478934695937</td>\n",
       "      <td>2019-12-23 21:49:08</td>\n",
       "      <td>kevinhookebot</td>\n",
       "      <td>\"Theim class=\\\"alignnone size-full wp-image-60...</td>\n",
       "      <td>kevinhooke-ml-bot</td>\n",
       "      <td>180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kevinhooke.com/wp-content/uplâ€¦</td>\n",
       "      <td>https://t.co/LiAsQsbs99</td>\n",
       "      <td>https://www.kevinhooke.com/wp-content/uploads/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA NA NA NA NA NA NA</td>\n",
       "      <td>https://twitter.com/kevinhookebot/status/12092...</td>\n",
       "      <td>Kevin Hooke Bot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm an AWS Lambda generating content from a Re...</td>\n",
       "      <td>https://t.co/gTSHg4mXqN</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6608</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-30 05:08:36</td>\n",
       "      <td>False</td>\n",
       "      <td>https://t.co/gTSHg4mXqN</td>\n",
       "      <td>https://www.kevinhooke.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://abs.twimg.com/sticky/default_profile_im...</td>\n",
       "      <td>2019-12-23 21:49:08</td>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>21:49:08</td>\n",
       "      <td>tweet</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "      <td>bot</td>\n",
       "      <td>kevinhooke</td>\n",
       "      <td>rnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20707</th>\n",
       "      <td>1538</td>\n",
       "      <td>x1197916267975335939</td>\n",
       "      <td>x1204245032917700608</td>\n",
       "      <td>2019-12-10 03:42:44</td>\n",
       "      <td>AINarendraModi</td>\n",
       "      <td>Met on the Abversion of our science for the co...</td>\n",
       "      <td>AI_Narendra_Modi</td>\n",
       "      <td>103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>life.Om</td>\n",
       "      <td>https://t.co/kl5Dfl0y18</td>\n",
       "      <td>http://life.Om</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA NA NA NA NA NA NA</td>\n",
       "      <td>https://twitter.com/AINarendraModi/status/1204...</td>\n",
       "      <td>AI Narendra Modi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Narendra Modi but with AI\\r\\nBot commands - ht...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1625</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-11-22 16:34:45</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/11979162...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1197916520...</td>\n",
       "      <td>2019-12-10 03:42:44</td>\n",
       "      <td>2019-12-10</td>\n",
       "      <td>03:42:44</td>\n",
       "      <td>tweet</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>bot</td>\n",
       "      <td>narendramodi</td>\n",
       "      <td>rnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20708</th>\n",
       "      <td>1885</td>\n",
       "      <td>x1197916267975335939</td>\n",
       "      <td>x1207011474243309570</td>\n",
       "      <td>2019-12-17 18:55:35</td>\n",
       "      <td>AINarendraModi</td>\n",
       "      <td>Land for their during the opportunity to the p...</td>\n",
       "      <td>AI_Narendra_Modi</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA NA NA NA NA NA NA</td>\n",
       "      <td>https://twitter.com/AINarendraModi/status/1207...</td>\n",
       "      <td>AI Narendra Modi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Narendra Modi but with AI\\r\\nBot commands - ht...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1625</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-11-22 16:34:45</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/11979162...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1197916520...</td>\n",
       "      <td>2019-12-17 18:55:35</td>\n",
       "      <td>2019-12-17</td>\n",
       "      <td>18:55:35</td>\n",
       "      <td>tweet</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>bot</td>\n",
       "      <td>narendramodi</td>\n",
       "      <td>rnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20709</th>\n",
       "      <td>3930</td>\n",
       "      <td>x705113652471439361</td>\n",
       "      <td>x715558455285837824</td>\n",
       "      <td>2016-03-31 15:16:44</td>\n",
       "      <td>DeepDrumpf</td>\n",
       "      <td>@TayandYou doesn't have a clue. You're right. ...</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>133</td>\n",
       "      <td>x714838749860012032</td>\n",
       "      <td>x78324623</td>\n",
       "      <td>eldiariodedross</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x4531940473 x78324623</td>\n",
       "      <td>TayandYou eldiariodedross</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA NA NA NA NA NA NA</td>\n",
       "      <td>https://twitter.com/DeepDrumpf/status/71555845...</td>\n",
       "      <td>DeepDrumpf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm a Neural Network trained on Trump's transc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>25401</td>\n",
       "      <td>7</td>\n",
       "      <td>296</td>\n",
       "      <td>286</td>\n",
       "      <td>19</td>\n",
       "      <td>2016-03-02 19:32:49</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/70511365...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/7054647353...</td>\n",
       "      <td>2016-03-31 15:16:44</td>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>15:16:44</td>\n",
       "      <td>reply</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>bot</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>rnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20710</th>\n",
       "      <td>729</td>\n",
       "      <td>x262794965</td>\n",
       "      <td>x812868913239199745</td>\n",
       "      <td>2016-12-25 03:53:45</td>\n",
       "      <td>jaden</td>\n",
       "      <td>Me And My Bestie https://t.co/vPq2iDkWZm</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>7265</td>\n",
       "      <td>1071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://pbs.twimg.com/media/C0fj97lUQAAT-dC.jpg</td>\n",
       "      <td>https://t.co/vPq2iDkWZm</td>\n",
       "      <td>https://twitter.com/officialjaden/status/81286...</td>\n",
       "      <td>photo</td>\n",
       "      <td>http://pbs.twimg.com/media/C0fj97lUQAAT-dC.jpg</td>\n",
       "      <td>https://t.co/vPq2iDkWZm</td>\n",
       "      <td>https://twitter.com/officialjaden/status/81286...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA NA NA NA NA NA NA</td>\n",
       "      <td>https://twitter.com/jaden/status/8128689132391...</td>\n",
       "      <td>Jaden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;U+0001F308&gt; Boy</td>\n",
       "      <td>https://t.co/2dZJOThjAQ</td>\n",
       "      <td>False</td>\n",
       "      <td>8142789</td>\n",
       "      <td>188</td>\n",
       "      <td>14893</td>\n",
       "      <td>5669</td>\n",
       "      <td>1844</td>\n",
       "      <td>2011-03-08 19:41:06</td>\n",
       "      <td>True</td>\n",
       "      <td>https://t.co/2dZJOThjAQ</td>\n",
       "      <td>https://jaden.link/erys</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://pbs.twimg.com/profile_banners/26279496...</td>\n",
       "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1146090110...</td>\n",
       "      <td>2016-12-25 03:53:45</td>\n",
       "      <td>2016-12-25</td>\n",
       "      <td>03:53:45</td>\n",
       "      <td>tweet</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>human</td>\n",
       "      <td>original</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20711</th>\n",
       "      <td>19366</td>\n",
       "      <td>x979586167405363200</td>\n",
       "      <td>x1194703766303338496</td>\n",
       "      <td>2019-11-13 19:49:09</td>\n",
       "      <td>kevinhookebot</td>\n",
       "      <td>\"Thead has a generate existing the Sparching f...</td>\n",
       "      <td>kevinhooke-ml-bot</td>\n",
       "      <td>205</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA</td>\n",
       "      <td>NA NA NA NA NA NA NA NA</td>\n",
       "      <td>https://twitter.com/kevinhookebot/status/11947...</td>\n",
       "      <td>Kevin Hooke Bot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm an AWS Lambda generating content from a Re...</td>\n",
       "      <td>https://t.co/gTSHg4mXqN</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6608</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-30 05:08:36</td>\n",
       "      <td>False</td>\n",
       "      <td>https://t.co/gTSHg4mXqN</td>\n",
       "      <td>https://www.kevinhooke.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://abs.twimg.com/sticky/default_profile_im...</td>\n",
       "      <td>2019-11-13 19:49:09</td>\n",
       "      <td>2019-11-13</td>\n",
       "      <td>19:49:09</td>\n",
       "      <td>tweet</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>bot</td>\n",
       "      <td>kevinhooke</td>\n",
       "      <td>rnn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20712 rows Ã— 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      N_prog               user_id  ... finetuning_source class_type\n",
       "0      14692  x1110407881030017024  ...           imranye     others\n",
       "1      22336           x3171109449  ...          original      human\n",
       "2      24087  x1110686081341632512  ...            zawvrk     others\n",
       "3       7584  x1110307772783124480  ...       ahadsheriff     others\n",
       "4      19654   x979586167405363200  ...        kevinhooke        rnn\n",
       "...      ...                   ...  ...               ...        ...\n",
       "20707   1538  x1197916267975335939  ...      narendramodi        rnn\n",
       "20708   1885  x1197916267975335939  ...      narendramodi        rnn\n",
       "20709   3930   x705113652471439361  ...   realDonaldTrump        rnn\n",
       "20710    729            x262794965  ...          original      human\n",
       "20711  19366   x979586167405363200  ...        kevinhooke        rnn\n",
       "\n",
       "[20712 rows x 103 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 7
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "c0oedq8-W7u2",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Select interesting columns for this study.\n",
    "dfTrainDataset = dfTrain[[\"screen_name\", \"text\", \"account.type\"]]\n",
    "dfValDataset = dfVal[[\"screen_name\", \"text\", \"account.type\"]]\n",
    "dfTestDataset = dfTest[[\"screen_name\", \"text\", \"account.type\"]]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qTeVpVc6I9Lb",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595436877732,
     "user_tz": -120,
     "elapsed": 596345,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "ebe528d8-a983-46a1-cae0-7f393f8ab32f"
   },
   "source": [
    "dfTrainDataset"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>account.type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>imranyebot</td>\n",
       "      <td>YEA now that note GOOD</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zawvrk</td>\n",
       "      <td>Listen to This Charming Man by The Smiths  htt...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zawarbot</td>\n",
       "      <td>wish i can i would be seeing other hoes on the...</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ahadsheriffbot</td>\n",
       "      <td>The decade in the significantly easier schedul...</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kevinhookebot</td>\n",
       "      <td>\"Theim class=\\\"alignnone size-full wp-image-60...</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20707</th>\n",
       "      <td>AINarendraModi</td>\n",
       "      <td>Met on the Abversion of our science for the co...</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20708</th>\n",
       "      <td>AINarendraModi</td>\n",
       "      <td>Land for their during the opportunity to the p...</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20709</th>\n",
       "      <td>DeepDrumpf</td>\n",
       "      <td>@TayandYou doesn't have a clue. You're right. ...</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20710</th>\n",
       "      <td>jaden</td>\n",
       "      <td>Me And My Bestie https://t.co/vPq2iDkWZm</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20711</th>\n",
       "      <td>kevinhookebot</td>\n",
       "      <td>\"Thead has a generate existing the Sparching f...</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20712 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          screen_name  ... account.type\n",
       "0          imranyebot  ...          bot\n",
       "1              zawvrk  ...        human\n",
       "2            zawarbot  ...          bot\n",
       "3      ahadsheriffbot  ...          bot\n",
       "4       kevinhookebot  ...          bot\n",
       "...               ...  ...          ...\n",
       "20707  AINarendraModi  ...          bot\n",
       "20708  AINarendraModi  ...          bot\n",
       "20709      DeepDrumpf  ...          bot\n",
       "20710           jaden  ...        human\n",
       "20711   kevinhookebot  ...          bot\n",
       "\n",
       "[20712 rows x 3 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 9
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yvFnZqKMIY4F",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "X_train_all = dfTrainDataset.drop(columns=['screen_name'])\n",
    "X_train_all.columns = [\"text\", \"label\"]\n",
    "\n",
    "X_val_all = dfValDataset.drop(columns=['screen_name'])\n",
    "X_val_all.columns = [\"text\", \"label\"]\n",
    "\n",
    "X_test_all = dfTestDataset.drop(columns=['screen_name'])\n",
    "X_test_all.columns = [\"text\", \"label\"]\n",
    "\n",
    "dictLabels = {\"human\":0, \"bot\":1}\n",
    "dictLabelsReverse = {0:\"human\", 1: \"bot\"}\n",
    "\n",
    "X_train_all[\"label\"] = X_train_all[\"label\"].apply(lambda x: dictLabels[x])\n",
    "X_val_all[\"label\"] = X_val_all[\"label\"].apply(lambda x: dictLabels[x])\n",
    "X_test_all[\"label\"] = X_test_all[\"label\"].apply(lambda x: dictLabels[x])\n",
    "y_train = X_train_all[\"label\"]\n",
    "y_val = X_val_all[\"label\"]\n",
    "y_test = X_test_all[\"label\"]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xDAhMIgmpxTs",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "train_labels = y_train.tolist()\n",
    "val_labels = y_val.tolist()\n",
    "test_labels = y_test.tolist()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QtE2szKKPis5",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 616,
     "referenced_widgets": [
      "053ab367f8a640c3966e2143370b2063",
      "114898f4262a4c219e3cad861bf2da41",
      "15ec6e25b60e4759b7ccf2fb8dc9e714",
      "4f71bed18e8c4384a5a82b32b9c67b64",
      "b16fb8dbc9e84100964be999cd468fce",
      "25a4e3418e5a4158937b1c968b33e2fb",
      "915f004a14784db3ae8edfaecd1c094a",
      "9d89bb9f68ed4ea89304489fc9dd7a84",
      "943a59bf412149e3a1ff863a1f1f8118",
      "387e66c97e1c43e9bbc472b9cd82d657",
      "b6decf24faf94ef0ab431ada40f5d21b",
      "ee40cf43e58348fa8bc3d734ee8b80c4",
      "e2a9aeaefb49472c8126b3571a0cdeb7",
      "f24715c13e4c4ec29074241d8200d10b",
      "7dc778ad60cf456799843c543d5f1008",
      "7991961b6aad4309860eec2a3edda7c5",
      "800f6695490d461c89c2b4a0501388b7",
      "d05b819f02fc4c9c895d4776521494a1",
      "e92c3a3a104a4b0ea9492e9b33952426",
      "a60a0eca898b417ab3e4aabcac1f972a",
      "cc32eda257914339a6e2123d38b6e100",
      "bf67f5e965e54f92aa5f0f711ec2afd9",
      "1901ef9bf4f04252bd2f8a95c215f580",
      "f535afc3db9649b7b683d8476e5061dc",
      "c4f7eabf95c94cb3947d76a4752d24ef",
      "d92fa367242c4f6dba668b69ee39ee00",
      "86ff0c90d30946f8869ef8e45adf2f3e",
      "7fcb9842c3ea405f8b1bb20b38003c4e",
      "ae9ffbbe7d3b4f10aa28c43713059046",
      "a0c1686dfae94710a21d5f49d56f5af5",
      "00e9cbd42fa9422ab8c99f4596f5b8a4",
      "eaafce605a844b378df4911e61553fdb",
      "53d43df9b742499c95db87975f4a2295",
      "d27c317dbd314034bfbd212d815dda82",
      "ad51f9664f034d49a18d6790ede25317",
      "616312f74242472587caf28b83897740",
      "502c09a0b5564bf7b55a3a7ce8abc0a1",
      "72f96435798b430a8a48b5e77e1a31fd",
      "fd6e6e366280474594d37a4b639d2b9b",
      "76ebf55da62a4d009907c36583e54854",
      "fad783d5155d40d8a2615d2c3e2f0671",
      "e55317524081456a89f0fc9a1a9cf8c5",
      "ded8bc0ea3d84cac8b2ef12e765afa0b",
      "a191f5a32f5a4c25820d3a168baee659",
      "6d813661f4134247afa96a17600ab4c4",
      "0f377f45c0e8496683c1a9b35a2aa5b7",
      "3ac11681d19645358d203b36fe2c49b8",
      "d5ce7cbf304649ac8863b4ac62279c3a",
      "67562766a9d54df88df7a6054c6c8e21",
      "a0c211973c6e44cf89b110da90008e27",
      "d71b7d9581dd4a26978fd81d48b17d0f",
      "0ec49a36d2c64ebea811c497901d3213",
      "438a05999c184781a26466373491a2ed",
      "f88db0f3657f410891ae5ef6b3a1552d",
      "98f098c661e54e21872886a3cc8d70e3",
      "5128dc9f677f4ad5b795d0afc4bff55c",
      "5dbfd446c379451780009b8f143b6047",
      "2d50eb838ff24726985edd208961b93c",
      "37eb915a80a54d15913d28f7ed61235c",
      "2ad0e76560b74fab825a68639890012c",
      "7632297b165f40beb5d0857dd8045b67",
      "18291f91d7c44753901bf3c17d523a19",
      "54714ba2b50a482aaa96849bfa7785c2",
      "248e8b6ac3e049daba8b0bb1265f468e"
     ]
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595441151755,
     "user_tz": -120,
     "elapsed": 4870357,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "36012dd3-bbd0-41ba-e75e-5c4e842b245f"
   },
   "source": [
    "from simpletransformers.classification import ClassificationModel\n",
    "\n",
    "# Create a ClassificationModel\n",
    "model = ClassificationModel('xlnet', 'xlnet-base-cased', args={'fp16': False, 'num_train_epochs': 3, \"overwrite_output_dir\":True}) # You can set class weights by using the optional weight argument\n",
    "\n",
    "# Train the model\n",
    "model.train_model(X_train_all)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "053ab367f8a640c3966e2143370b2063",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=760.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943a59bf412149e3a1ff863a1f1f8118",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=467042463.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800f6695490d461c89c2b4a0501388b7",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=798011.0, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/simpletransformers/classification/classification_model.py:270: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  \"Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\"\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f7eabf95c94cb3947d76a4752d24ef",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20712.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53d43df9b742499c95db87975f4a2295",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='iâ€¦"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad783d5155d40d8a2615d2c3e2f0671",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 0', max=2589.0, style=ProgressStyle(descripâ€¦"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "Running loss: 0.600029"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:231: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Running loss: 0.059217"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Running loss: 0.144550\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67562766a9d54df88df7a6054c6c8e21",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 1', max=2589.0, style=ProgressStyle(descripâ€¦"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "Running loss: 0.120430\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dbfd446c379451780009b8f143b6047",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 2', max=2589.0, style=ProgressStyle(descripâ€¦"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "Running loss: 0.007419\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IMw6mBUziwFA",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169,
     "referenced_widgets": [
      "27857b2e9871485eb9d0978faf23c866",
      "45e60f62ffbb425896008eee6d015161",
      "052327fd6c624c3abdd89b393e0d187a",
      "fb6b2483b7724c32882ab3ae9853eb0d",
      "48dea92eda0c411699d04b64aef3d3eb",
      "e13eb1d43e5242f99fa29c0c16889de1",
      "07d9d084bb8d407cb8f8ddd4cfa96528",
      "c185a0bc13244499a10b7aa52642f797",
      "3aaf0fee85f4467a93d37fed31f56a66",
      "252274bcfb8847c9a881d3c46da3fd94",
      "743a423f83004eccb5a713545bfc2eca",
      "f1222464f0f744dea491133def101f85",
      "49f279f8a8ba4d09baaab01bb7f1ba7c",
      "027780d27f204cda8348e1527fdaaa02",
      "7fe5edeb3b75488aab28385875d71d36",
      "34674ad05d3f442f8dfc70918952edbc"
     ]
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595441218481,
     "user_tz": -120,
     "elapsed": 4937076,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "d6e2ab5e-4b23-4f4e-e9f6-da41d12549e8"
   },
   "source": [
    "# Evaluate the model\n",
    "import sklearn\n",
    "result, model_outputs, wrong_predictions = model.eval_model(X_test_all, acc=sklearn.metrics.accuracy_score, f1=sklearn.metrics.f1_score)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/simpletransformers/classification/classification_model.py:691: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  \"Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\"\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27857b2e9871485eb9d0978faf23c866",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2558.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aaf0fee85f4467a93d37fed31f56a66",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Evaluation', max=320.0, style=ProgressStyle(descrâ€¦"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "o7svswrNjIjK",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595441218482,
     "user_tz": -120,
     "elapsed": 4937070,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "ccada175-8598-467b-d765-036ab10d66b2"
   },
   "source": [
    "result"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'acc': 0.8764659890539483,\n",
       " 'eval_loss': 0.47897766475798564,\n",
       " 'f1': 0.8739026336791701,\n",
       " 'fn': 185,\n",
       " 'fp': 131,\n",
       " 'mcc': 0.753611921450544,\n",
       " 'tn': 1147,\n",
       " 'tp': 1095}"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 14
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HIR3WEA1XMw7",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115,
     "referenced_widgets": [
      "72f233123c1a40c68d42348f0fa991f8",
      "748e60c78d8a4d75a6c9fbfadb4d1a55",
      "db374a6d0f2c4259964bb407aa1d3e8f",
      "a2ae6b43c6984e908449d038ff95d142",
      "3d93f3c927cb468981082bebea2a05a5",
      "d6c7549b582f41c9983281b55b83b335",
      "c10c4f05008944ca87d7a87828ede99e",
      "e428be8baa334b24a7d82fc9f574ea76",
      "a1b9ef62a27047819c18c6a7b2402354",
      "d738e7d64eeb48c5ae86a3ce1de2b292",
      "ba18ce88f86f48d2ae925a576108e52e",
      "88ec80ef321d481d871baf3ff50aab2f",
      "2c69b8d61ebe44e985d8dd5afb9197aa",
      "f7afed5a93f54a9d9328c9d66e44a2f6",
      "709296532d064c37b995fa04eea6b80a",
      "052bfb48725c44dbad7422c688205d4b"
     ]
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595441279554,
     "user_tz": -120,
     "elapsed": 4998136,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "e8698045-70e5-44f8-e7d0-006e07dfccc3"
   },
   "source": [
    "predictions = model.predict(X_test_all[\"text\"])[0]"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72f233123c1a40c68d42348f0fa991f8",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2558.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b9ef62a27047819c18c6a7b2402354",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=320.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kQh7M9FWclnE",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "predictionLabels = [dictLabelsReverse[t] for t in predictions]\n",
    "dfResults = pd.DataFrame(predictionLabels, columns=[\"prediction\"])\n",
    "dfResults[\"gold\"] = dfTest[[\"account.type\"]]\n",
    "file_name = resultsDir+\"/xlnet_finetuning.csv\"\n",
    "dfResults.to_csv(file_name, sep='\\t', encoding='utf-8')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cGwuVWcsaZse",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "dfTest[\"label_xlnet\"] = [dictLabelsReverse[t] for t in predictions]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5z4JICTNSTbX",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def plotErrorRatio(X_test_all, prediction_column, min_sample_num=30):\n",
    "  X_verify = X_test_all[[\"screen_name\", \"text\", \"account.type\", prediction_column]]\n",
    "  X_count_accounts = X_test_all[[\"screen_name\", \"account.type\"]].groupby(\"screen_name\").count()\n",
    "  X_verify = X_verify[X_verify[\"account.type\"] != X_verify[prediction_column]]\n",
    "  X_verify = X_verify.groupby(\"screen_name\").count()[\"text\"].to_frame()\n",
    "  X_verify[\"total\"] = X_count_accounts[\"account.type\"]\n",
    "  X_verify.columns = [\"errors\", \"num_samples\"]\n",
    "  X_verify[\"error_ratio\"] = X_verify[\"errors\"] / X_verify[\"num_samples\"]\n",
    "  X_verify[X_verify[\"num_samples\"] >= min_sample_num][\"error_ratio\"].plot.bar(figsize=(15,5))\n",
    "  return X_verify"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HkD_xLJ9zCRR",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1595441281505,
     "user_tz": -120,
     "elapsed": 5000075,
     "user": {
      "displayName": "tizfa data",
      "photoUrl": "",
      "userId": "14479436635515447323"
     }
    },
    "outputId": "3bd95c07-0c1a-4d50-ce12-c158fe601727"
   },
   "source": [
    "plotErrorRatio(dfTest, \"label_xlnet\")"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>errors</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>error_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>screen_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AINarendraModi</th>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>0.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepDrumpf</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DrilRnn</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GenePark</th>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GenePark_GPT2</th>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>0.318182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gpt2Wint</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Musk_from_Mars</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thorin</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtilityLimb</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VitalikButerin</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ahadsheriff</th>\n",
       "      <td>11</td>\n",
       "      <td>95</td>\n",
       "      <td>0.115789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ahadsheriffbot</th>\n",
       "      <td>10</td>\n",
       "      <td>95</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awhalefact</th>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>0.085714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>botustrump</th>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>0.085714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calebgamman</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calebgamman2</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deep_thorin</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dril</th>\n",
       "      <td>45</td>\n",
       "      <td>180</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dril_gpt2</th>\n",
       "      <td>77</td>\n",
       "      <td>179</td>\n",
       "      <td>0.430168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elonmusk</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2_trump</th>\n",
       "      <td>8</td>\n",
       "      <td>55</td>\n",
       "      <td>0.145455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imranye</th>\n",
       "      <td>12</td>\n",
       "      <td>129</td>\n",
       "      <td>0.093023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imranyebot</th>\n",
       "      <td>20</td>\n",
       "      <td>129</td>\n",
       "      <td>0.155039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jaden</th>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kevinhooke</th>\n",
       "      <td>3</td>\n",
       "      <td>241</td>\n",
       "      <td>0.012448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kevinhookebot</th>\n",
       "      <td>3</td>\n",
       "      <td>241</td>\n",
       "      <td>0.012448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>narendramodi</th>\n",
       "      <td>2</td>\n",
       "      <td>124</td>\n",
       "      <td>0.016129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ninjasexparty</th>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>0.391304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nsp_gpt2</th>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>0.347826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realDonaldTrump</th>\n",
       "      <td>9</td>\n",
       "      <td>129</td>\n",
       "      <td>0.069767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sarcastic_trump</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theJadenTrudeau</th>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>0.038835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whalefakes</th>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>0.114286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zawarbot</th>\n",
       "      <td>29</td>\n",
       "      <td>152</td>\n",
       "      <td>0.190789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zawvrk</th>\n",
       "      <td>21</td>\n",
       "      <td>152</td>\n",
       "      <td>0.138158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 errors  num_samples  error_ratio\n",
       "screen_name                                      \n",
       "AINarendraModi        1          125     0.008000\n",
       "DeepDrumpf            1           29     0.034483\n",
       "DrilRnn               1            1     1.000000\n",
       "GenePark              2           22     0.090909\n",
       "GenePark_GPT2         7           22     0.318182\n",
       "Gpt2Wint              1            2     0.500000\n",
       "Musk_from_Mars        1            2     0.500000\n",
       "Thorin                1           10     0.100000\n",
       "UtilityLimb           3            4     0.750000\n",
       "VitalikButerin        1           13     0.076923\n",
       "ahadsheriff          11           95     0.115789\n",
       "ahadsheriffbot       10           95     0.105263\n",
       "awhalefact            3           35     0.085714\n",
       "botustrump            3           35     0.085714\n",
       "calebgamman           5           13     0.384615\n",
       "calebgamman2          4           13     0.307692\n",
       "deep_thorin           2           10     0.200000\n",
       "dril                 45          180     0.250000\n",
       "dril_gpt2            77          179     0.430168\n",
       "elonmusk              1            6     0.166667\n",
       "gpt2_trump            8           55     0.145455\n",
       "imranye              12          129     0.093023\n",
       "imranyebot           20          129     0.155039\n",
       "jaden                 3           51     0.058824\n",
       "kevinhooke            3          241     0.012448\n",
       "kevinhookebot         3          241     0.012448\n",
       "narendramodi          2          124     0.016129\n",
       "ninjasexparty         9           23     0.391304\n",
       "nsp_gpt2              8           23     0.347826\n",
       "realDonaldTrump       9          129     0.069767\n",
       "sarcastic_trump       1            5     0.200000\n",
       "theJadenTrudeau       4          103     0.038835\n",
       "whalefakes            4           35     0.114286\n",
       "zawarbot             29          152     0.190789\n",
       "zawvrk               21          152     0.138158"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 19
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MFxq59MLEtkh",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}